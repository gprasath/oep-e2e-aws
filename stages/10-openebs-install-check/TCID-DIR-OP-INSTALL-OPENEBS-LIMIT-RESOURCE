#!/bin/bash

set -x

######################
##   Prerequisites  ##
######################

path=$(pwd)
# Copy kubeconfig
mkdir -p ~/.kube
cp  $path/.awscluster3/config ~/.kube/config
cp .kube/$CLUSTER ~/.kube/$CLUSTER

####################################
##  Sequencing and Running test   ##
####################################

bash utils/pooling jobname:tcid-dir-op-re-install-openebs
bash utils/e2e-cr jobname:tcid-dir-op-install-openebs-limit-resource jobphase:Running

echo "********** Check Filesystem state **********"
{
    kubectl get bd -n openebs -ojsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.labels.kubernetes\.io/hostname}{"\t"}{.status}{"\t"}{.spec.filesystem}{"\t"}{"\n"}{end}'
} || {
    echo "******* BD is not present *******"
}

## volumes
COUNTER=1
echo '#### AWS CONFIG ####'
mkdir -p ~/.aws
cp $AWS_CREDS ~/.aws/credentials
sed 's|region = eu-central-1|region = us-west-2|' -i ~/.aws/config

##kubectl get disks

git clone https://github.com/mayadata-io/litmus.git
cd litmus/k8s/aws/ebs-volumes

sed 's|region: eu-west-2|region: us-west-2|' -i ./vars.yml
sed 's|zone: eu-west-2a|zone: us-west-2a|' -i ./vars.yml
sed 's|volume_size: 50|volume_size: 20|' -i ./vars.yml
clustername=$(cat ~/.kube/$CLUSTER)
#chars=( {f..p} )
cat vars.yml
# NEWNUMBEROFVOLUMES=NUMBEROFVOLUMES+1

# while [  $COUNTER -lt "$NEWNUMBEROFVOLUMES" ]; do
#     chr="${chars[$COUNTER]}"

#     ansible-playbook create-ebs-volume.yml -vv --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local device_name=/dev/sd$chr"
#     let COUNTER=COUNTER+1

echo '#### DISK 1 ####'

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 2 ####'

sed -i 's/device_name: \/dev\/xvdb/device_name: \/dev\/xvdc/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 3 ####'

sed -i 's/device_name: \/dev\/xvdc/device_name: \/dev\/xvdd/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 4 ####'

sed -i 's/device_name: \/dev\/xvdd/device_name: \/dev\/xvde/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 5 ####'

sed -i 's/device_name: \/dev\/xvde/device_name: \/dev\/xvdf/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 6 ####'

sed -i 's/device_name: \/dev\/xvdf/device_name: \/dev\/xvdg/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 7 ####'

sed -i 's/device_name: \/dev\/xvdg/device_name: \/dev\/xvdh/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 8 ####'

sed -i 's/device_name: \/dev\/xvdh/device_name: \/dev\/xvdi/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

echo '#### DISK 9 ####'

sed -i 's/device_name: \/dev\/xvdi/device_name: \/dev\/xvdj/g' vars.yml

ansible-playbook create-ebs-volume.yml --extra-vars "cluster_name=nodes.k8s-$clustername.k8s.local" -vv

##kubectl get disks

sleep 30
aws s3 cp /tmp/aws/volume-id s3://k8s-bucket-$clustername
sleep 30

kubectl get bd -n openebs -ojsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.labels.kubernetes\.io/hostname}{"\t"}{.status}{"\t"}{.spec.filesystem}{"\t"}{"\n"}{end}'

cd ../../../..
# Cloning oep-e2e repository which contains all the test scripts
git clone https://$username:$password@github.com/mayadata-io/oep-e2e.git


kubectl create -f oep-e2e/litmus/director/TCID-DIR-OP-INSTALL-OPENEBS-LIMIT-RESOURCE/run_litmus_test.yml
kubectl get pods -n litmus

test_name=openebs-resource-limit-installation
echo $test_name

## E2E Test case plan link
e2e_tc_plan_link=https://e2e.mayadata.io/docs/director/openebs-provisioning/TCID-DIR-OP-INSTALL-OPENEBS-LIMIT-RESOURCE
echo -e "\nTC_E2E_PLAN_LINK: $e2e_tc_plan_link\n"

litmus_pod=$(kubectl get po -n litmus | grep $test_name  | awk {'print $1'} | tail -n 1)
echo $litmus_pod

job_status=$(kubectl get po  $litmus_pod -n litmus | awk {'print $3'} | tail -n 1)

while [[ "$job_status" != "Completed" ]]
do 
    job_status=$(kubectl get po  $litmus_pod -n litmus | awk {'print $3'} | tail -n 1)
    sleep 6
done

echo "********** Check Filesystem state **********"
kubectl get bd -n openebs -ojsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.labels.kubernetes\.io/hostname}{"\t"}{.status}{"\t"}{.spec.filesystem}{"\t"}{"\n"}{end}'

kubectl logs -f $litmus_pod -n litmus
testResult=$(kubectl get litmusresult ${test_name} --no-headers -o custom-columns=:spec.testStatus.result)
echo $testResult

if [ "$testResult" != Pass ]
then 
    exit 1;
else
    bash utils/e2e-cr jobname:tcid-dir-op-install-openebs-limit-resource jobphase:Completed
fi 